# ğŸ“Š Adâ€‘Techâ€¯ETLâ€¯Pipeline onâ€¯Azure

*A fullyâ€‘serverless, productionâ€‘ready data pipeline for advertising performance analytics*

---

![Azure](https://img.shields.io/badge/Cloud-Azure-blue) ![ETL](https://img.shields.io/badge/Type-Serverless%20ETL-green) 

> **TL;DR** â€“ This repository contains the code, scripts, and architecture for an endâ€‘toâ€‘end ETL pipeline that ingests raw JSON adâ€‘performance data, transforms it using Synapseâ€¯Serverless, and surfaces curated, analyticsâ€‘ready tables to Powerâ€¯BI â€“ all orchestrated with Azureâ€¯Dataâ€¯Factory.

---

## ğŸ“š Tableâ€¯ofâ€¯Contents

1. [Projectâ€¯Goals](#project-goals)
2. [Architectureâ€¯Overview](#architecture-overview)
3. [Technologyâ€¯Stack](#technology-stack)
4. [Pipelineâ€¯Executionâ€¯Flow](#pipeline-execution-flow)
5. [Dataâ€¯ModelÂ â€“Â MedallionÂ Architecture](#data-model--medallion-architecture)
6. [SetupÂ &Â Deployment](#setup--deployment)
7. [KeyÂ ChallengesÂ &Â Solutions](#key-challenges--solutions)
8. [Roadmap](#roadmap)
9. [Contributing](#contributing)
10. [License](#license)

---

## ğŸ¯ Projectâ€¯Goals

* **SingleÂ Sourceâ€¯ofâ€¯Truth** â€“ Consolidate multiâ€‘platform ad data into a unified, queryâ€‘ready model.
* **Costâ€‘Efficient & Scalable** â€“ Leverage Azureâ€™s payâ€‘asâ€‘youâ€‘go, serverless services to minimise idle spend.
* **Productionâ€‘Grade** â€“ Include idempotency, robust security (Managed Identities), and automated orchestration.
* **BIâ€‘Ready** â€“ Deliver daily campaign KPIs such as ROAS directly to Powerâ€¯BI for selfâ€‘service analytics.

---

## ğŸ—ï¸ Architectureâ€¯Overview

```mermaid
flowchart LR
    subgraph Azure
        ADLS["ADLSÂ Gen2\n(Bronze / Silver / Gold)"]
        Synapse["SynapseÂ Analytics\nServerlessÂ SQLÂ Pools"]
        ADF["AzureÂ DataÂ Factory\nPipeline"]
        PowerBI["PowerÂ BIÂ Dashboard"]
    end
    ADLS -->|RawÂ NDJSON| Synapse
    Synapse -- ParquetÂ --> ADLS
    ADF -- orchestrates --> Synapse
    ADLS -->|GoldÂ Parquet| PowerBI
```

* **Serverlessâ€‘Only** â€“ No longâ€‘running clusters or dedicated SQL pools.
* **SequentialÂ orchestration** ensures data integrity with builtâ€‘in retry & error handling.

---

## ğŸ› ï¸ Technologyâ€¯Stack

| Layer         | Service                                | Details                                     |
| ------------- | -------------------------------------- | ------------------------------------------- |
| Storage       | **AzureÂ DataÂ LakeÂ Storageâ€¯Gen2**       | Raw (NDJSON) & curated (Parquet) zones      |
| Transform     | **AzureÂ SynapseÂ ServerlessÂ SQLÂ Pools** | Tâ€‘SQL cleansing, typeâ€‘casting, aggregations |
| Orchestration | **AzureÂ DataÂ Factory**                 | Pipeline `PL_Daily_Ad_Performance_ETL`      |
| Modelling     | **MedallionÂ (Bronze/Silver/Gold)**     | Incremental refinement pattern              |
| Reporting     | **PowerÂ BI**                           | DirectLake/Import mode                      |
| Scripting     | `Python`                               | Sampleâ€‘data generator                       |

---

## âš™ï¸ Pipelineâ€¯Executionâ€¯Flow

1. **SetupÂ DataÂ Sources** â€“ Creates `MASTERÂ KEY` & `EXTERNALÂ DATAÂ SOURCE` objects pointing to ADLS containers.
2. **DeleteÂ OldÂ SilverÂ Data** â€“ Ensures idempotency by removing yesterdayâ€™s Parquet partitions.
3. **BronzeÂ â†’Â SilverÂ ETL** â€“ Cleans NDJSON, enforces schema, writes partitioned Parquet to **Silver**.
4. **DeleteÂ OldÂ GoldÂ Data** â€“ Clears previous aggregates.
5. **SilverÂ â†’Â GoldÂ ETL** â€“ Aggregates campaignâ€‘level KPIs, outputs Parquet optimised for BI.

> All steps run inside a single ADF pipeline for ease of monitoring and alerting.

---

## ğŸ—‚ï¸ Dataâ€¯ModelÂ â€“Â MedallionÂ Architecture

| Layer      | StorageÂ Path                              | Purpose                              |
| ---------- | ----------------------------------------- | ------------------------------------ |
| **Bronze** | `adls://bronze/<date>/ad_data.ndjson`     | Immutable raw ingest                 |
| **Silver** | `adls://silver/ad_performance/`           | Cleansed, typed, partitioned Parquet |
| **Gold**   | `adls://gold/daily_campaign_performance/` | BIâ€‘ready daily aggregates            |

---

## ğŸš€ SetupÂ &Â Deployment

```bash
# 1ï¸âƒ£Â Clone repo & install deps
$ git clone https://github.com/<yourâ€‘org>/ad-tech-etl-pipeline.git
$ cd ad-tech-etl-pipeline

# 2ï¸âƒ£Â Generate sample data & upload to Bronze (local run)
$ python data_generator/upload_ad_data.py --account <storageâ€‘acct> --container bronze

# 3ï¸âƒ£Â Deploy Azure resources (ARM/Bicep coming soon)
# az deployment group create ...

# 4ï¸âƒ£Â Import ADF pipeline JSON via AzureÂ Portal & Publish
```

> **Tip:** For CI/CD, export the ADF ARM template after publishing and plug it into your pipeline of choice (GitHub Actions / Azure DevOps).

---

## ğŸ§© Keyâ€¯ChallengesÂ &Â Solutions

| Challenge                                         | Solution                                                                    |
| ------------------------------------------------- | --------------------------------------------------------------------------- |
| *OPENROWSET rowâ€‘size limits with multiâ€‘line JSON* | Switched to **NDJSON** format â€“ one JSON object per line.                   |
| *Complex crossâ€‘service permissions*               | Implemented **AzureÂ ManagedÂ Identities** + explicit RBAC on ADLS & Synapse. |
| *Nonâ€‘idempotent external table creates*           | Added ADF **Delete** activities before each ETL stage.                      |

---

## ğŸ—ºï¸ Roadmap

* [ ] Infrastructureâ€‘asâ€‘Code (Bicep) templates
* [ ] Unit & integration tests (tâ€‘SQLt / pytestâ€‘sql)
* [ ] CI/CD via GitHubÂ Actions
* [ ] Costâ€‘monitoring dashboards

---

## ğŸ¤ Contributing

PRs are welcome! Please open an issue first to discuss major changes. Make sure CI passes and commit messages follow **Conventionalâ€¯Commits**.

---

